{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61e668ee",
   "metadata": {},
   "source": [
    "## 1. Scraping all header tags from wiki main page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0eb7221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2757d982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://en.wikipedia.org/wiki/Main_Page')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f742f8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(page.content)\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbcf07e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Welcome to Wikipedia',\n",
       " \"From today's featured article\",\n",
       " 'Did you know\\xa0...',\n",
       " 'In the news',\n",
       " 'On this day',\n",
       " \"Today's featured picture\",\n",
       " 'Other areas of Wikipedia',\n",
       " \"Wikipedia's sister projects\",\n",
       " 'Wikipedia languages']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head = []\n",
    "for i in soup.find_all('span',class_ = 'mw-headline'):\n",
    "    head.append(i.text)\n",
    "head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5678de4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Header</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome to Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From today's featured article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Did you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On this day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Today's featured picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Other areas of Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wikipedia's sister projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wikipedia languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Header\n",
       "0           Welcome to Wikipedia\n",
       "1  From today's featured article\n",
       "2               Did you know ...\n",
       "3                    In the news\n",
       "4                    On this day\n",
       "5       Today's featured picture\n",
       "6       Other areas of Wikipedia\n",
       "7    Wikipedia's sister projects\n",
       "8            Wikipedia languages"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Header'] = head\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dbd145",
   "metadata": {},
   "source": [
    "## 2. Scraping IMDB's top rated 100 movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f51145c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.imdb.com/list/ls091520106/')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10d33e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(page.text,'html.parser')\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68efa33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "for i in soup.find_all('h3', class_ = 'lister-item-header'):\n",
    "    names.append(i.find('a').text)\n",
    "#names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94a6e218",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = []\n",
    "for i in soup.find_all('div',class_ = 'ipl-rating-widget'):\n",
    "    ratings.append(i.find('span',class_ = 'ipl-rating-star__rating').text)\n",
    "#ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da111f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = []\n",
    "for i in soup.find_all('span',class_ = 'lister-item-year text-muted unbold'):\n",
    "    year.append(i.text)\n",
    "#year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc2b050e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie name</th>\n",
       "      <th>Ratings out of 10</th>\n",
       "      <th>Year of release</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>9.3</td>\n",
       "      <td>(1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>9.2</td>\n",
       "      <td>(1972)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather Part II</td>\n",
       "      <td>9</td>\n",
       "      <td>(1974)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>9</td>\n",
       "      <td>(2008)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>9</td>\n",
       "      <td>(1957)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1959)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1971)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Snatch</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Le fabuleux destin d'Amélie Poulain</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Kid</td>\n",
       "      <td>8.3</td>\n",
       "      <td>(1921)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Movie name Ratings out of 10 Year of release\n",
       "0              The Shawshank Redemption               9.3          (1994)\n",
       "1                         The Godfather               9.2          (1972)\n",
       "2                 The Godfather Part II                 9          (1974)\n",
       "3                       The Dark Knight                 9          (2008)\n",
       "4                          12 Angry Men                 9          (1957)\n",
       "..                                  ...               ...             ...\n",
       "95                   North by Northwest               8.3          (1959)\n",
       "96                   A Clockwork Orange               8.3          (1971)\n",
       "97                               Snatch               8.3          (2000)\n",
       "98  Le fabuleux destin d'Amélie Poulain               8.3          (2001)\n",
       "99                              The Kid               8.3          (1921)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datF = pd.DataFrame({'Movie name':names,'Ratings out of 10':ratings,'Year of release':year})\n",
    "datF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6005ef",
   "metadata": {},
   "source": [
    "## 3. Scraping top 100 Indian Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49e50f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.imdb.com/india/top-rated-indian-movies/')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00db0e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(page.content,'html.parser')\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09f410f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "for i in soup.find_all('td',class_ = 'titleColumn'):\n",
    "    name.append(i.find('a').text)\n",
    "name = name[0:100]\n",
    "#name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3569f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = []\n",
    "for i in soup.find_all('td',class_ = 'ratingColumn imdbRating'):\n",
    "    ratings.append(i.find('strong').text)\n",
    "ratings = ratings[0:100]\n",
    "#ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18a718b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = []\n",
    "for i in soup.find_all('span',class_ = 'secondaryInfo'):\n",
    "    year.append(i.text)\n",
    "year = year[0:100]\n",
    "#year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4ef1da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie name</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Release year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jai Bhim</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2021)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2003)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Golmaal</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1979)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(1987)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pariyerum Perumal</td>\n",
       "      <td>8.4</td>\n",
       "      <td>(2018)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Baasha</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Masaan</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(2015)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Kahaani</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(2012)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Baahubali 2: The Conclusion</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Dil Chahta Hai</td>\n",
       "      <td>8.0</td>\n",
       "      <td>(2001)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Movie name Ratings Release year\n",
       "0                      Jai Bhim     8.4       (2021)\n",
       "1                    Anbe Sivam     8.4       (2003)\n",
       "2                       Golmaal     8.4       (1979)\n",
       "3                       Nayakan     8.4       (1987)\n",
       "4             Pariyerum Perumal     8.4       (2018)\n",
       "..                          ...     ...          ...\n",
       "95                       Baasha     8.0       (1995)\n",
       "96                       Masaan     8.0       (2015)\n",
       "97                      Kahaani     8.0       (2012)\n",
       "98  Baahubali 2: The Conclusion     8.0       (2017)\n",
       "99               Dil Chahta Hai     8.0       (2001)\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataF = pd.DataFrame({'Movie name':name,'Ratings':ratings,'Release year':year})\n",
    "dataF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fd76e3",
   "metadata": {},
   "source": [
    "## 4. Scraping of President names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4912ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://presidentofindia.nic.in/former-presidents.htm')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cac636d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(page.content,'html.parser')\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02a9fdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "for i in soup.find_all('div', class_ = 'presidentListing'):\n",
    "    name.append(i.find('h3').text.split(\"(\")[0])\n",
    "#name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ec13585",
   "metadata": {},
   "outputs": [],
   "source": [
    "term = []\n",
    "for i in soup.find_all('div', class_ = 'presidentListing'):\n",
    "    term.append(i.find('p').text.split(\"Term of Office:\")[1])\n",
    "#term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d80ac131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Term of office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Pranab Mukherjee</td>\n",
       "      <td>25 July, 2012 to 25 July, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Smt Pratibha Devisingh Patil</td>\n",
       "      <td>25 July, 2007 to 25 July, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam</td>\n",
       "      <td>25 July, 2002 to 25 July, 2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shri K. R. Narayanan</td>\n",
       "      <td>25 July, 1997 to 25 July, 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dr Shankar Dayal Sharma</td>\n",
       "      <td>25 July, 1992 to 25 July, 1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Shri R Venkataraman</td>\n",
       "      <td>25 July, 1987 to 25 July, 1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Giani Zail Singh</td>\n",
       "      <td>25 July, 1982 to 25 July, 1987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy</td>\n",
       "      <td>25 July, 1977 to 25 July, 1982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed</td>\n",
       "      <td>24 August, 1974 to 11 February, 1977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Shri Varahagiri Venkata Giri</td>\n",
       "      <td>3 May, 1969 to 20 July, 1969 and 24 August, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Dr. Zakir Husain</td>\n",
       "      <td>13 May, 1967 to 3 May, 1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan</td>\n",
       "      <td>13 May, 1962 to 13 May, 1967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Rajendra Prasad</td>\n",
       "      <td>26 January, 1950 to 13 May, 1962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name  \\\n",
       "0          Shri Pranab Mukherjee    \n",
       "1   Smt Pratibha Devisingh Patil    \n",
       "2         DR. A.P.J. Abdul Kalam    \n",
       "3           Shri K. R. Narayanan    \n",
       "4        Dr Shankar Dayal Sharma    \n",
       "5            Shri R Venkataraman    \n",
       "6               Giani Zail Singh    \n",
       "7      Shri Neelam Sanjiva Reddy    \n",
       "8       Dr. Fakhruddin Ali Ahmed    \n",
       "9   Shri Varahagiri Venkata Giri    \n",
       "10              Dr. Zakir Husain    \n",
       "11  Dr. Sarvepalli Radhakrishnan    \n",
       "12           Dr. Rajendra Prasad    \n",
       "\n",
       "                                       Term of office  \n",
       "0                     25 July, 2012 to 25 July, 2017   \n",
       "1                     25 July, 2007 to 25 July, 2012   \n",
       "2                     25 July, 2002 to 25 July, 2007   \n",
       "3                     25 July, 1997 to 25 July, 2002   \n",
       "4                     25 July, 1992 to 25 July, 1997   \n",
       "5                     25 July, 1987 to 25 July, 1992   \n",
       "6                     25 July, 1982 to 25 July, 1987   \n",
       "7                     25 July, 1977 to 25 July, 1982   \n",
       "8                24 August, 1974 to 11 February, 1977  \n",
       "9    3 May, 1969 to 20 July, 1969 and 24 August, 1...  \n",
       "10                        13 May, 1967 to 3 May, 1969  \n",
       "11                       13 May, 1962 to 13 May, 1967  \n",
       "12                   26 January, 1950 to 13 May, 1962  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Name'] = name\n",
    "df['Term of office'] = term\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b941c5a6",
   "metadata": {},
   "source": [
    "# 5. Scraping cricket rankings\n",
    "### (a) Top 10 ODI Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d3c6d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4364087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(page.content, 'html.parser')\n",
    "#soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40070ea0",
   "metadata": {},
   "source": [
    "#### matches, points and rating for New Zealand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e115f41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1'], ['New', 'Zealand', 'NZ'], ['12'], ['1,505'], ['125']]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nz = []\n",
    "for i in soup.find('tr',class_=\"rankings-block__banner\"):\n",
    "    nz.append(i.text.split())\n",
    "nz = list(filter(None,nz))\n",
    "nz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033ad65f",
   "metadata": {},
   "source": [
    "#### matches, points and rating for other teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ab96a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = []\n",
    "for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "    matches.append(i.find('td', class_=\"table-body__cell u-center-text\").text)\n",
    "#matches\n",
    "\n",
    "teams_all = []\n",
    "for i in soup.find_all('tr',class_=\"table-body\"):\n",
    "    teams_all.append(i.text.split())\n",
    "#teams_all\n",
    "\n",
    "team = []\n",
    "for i in teams_all[::]:\n",
    "    team.append(i)\n",
    "team = team[:9]\n",
    "#team"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f439bf8",
   "metadata": {},
   "source": [
    "# 7. News details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6690e7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get(\"https://www.cnbc.com/world/?region=world\")\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cab55943",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(page.content,'html.parser')\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2acc59fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "headline = []\n",
    "for i in soup.find_all('a',class_ = \"LatestNews-headline\"):\n",
    "    headline.append(i.text)\n",
    "#headline\n",
    "\n",
    "time = []\n",
    "for i in soup.find_all('span',class_=\"LatestNews-wrapper\"):\n",
    "    time.append(i.text)\n",
    "#time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "61e44004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headline</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Netflix lays off 300 more employees as revenue...</td>\n",
       "      <td>19 Min Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GOP draft bill would tighten rules for finance...</td>\n",
       "      <td>24 Min Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Santoli: The S&amp;P 500’s bounce is set to face a...</td>\n",
       "      <td>40 Min Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stocks making the biggest moves midday: WeWork...</td>\n",
       "      <td>44 Min Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We're trimming a winner to raise some cash and...</td>\n",
       "      <td>49 Min Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Intel warns Ohio factory could be delayed</td>\n",
       "      <td>52 Min Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>First half ranks among the market’s worst on r...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What we can learn about inflation, consumers f...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How to save money at the pump, with or without...</td>\n",
       "      <td>1 Hour Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Instagram is testing new ways for teens to ver...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Proposed changes to retirement system get appr...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>High inflation has 58% feeling insecure about ...</td>\n",
       "      <td>2 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Supreme Court strikes down NY gun law restrict...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FDA bans Juul e-cigarettes as government pursu...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Tax return backlog is still 'crushing the IRS’...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Education Department to cancel student loan de...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Watch Jerome Powell testify to Congress on the...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Jan. 6 hearing to spotlight Trump's pressure o...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Warren Buffett buys another $500 million of Oc...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A 30-year Wall Street veteran on his tips for ...</td>\n",
       "      <td>3 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chinese EV maker Nio says a car fell from thir...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>JPMorgan sees no recession, 28% S&amp;P 500 comeba...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Chipotle restaurant in Maine becomes chain's f...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>JPMorgan upgrades Funko, says toy stock has up...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>What Cramer is watching Thursday — Meta's big ...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>What Biden's upcoming student loan forgiveness...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Bethenny Frankel's top spending advice: 'It ha...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Forget Silicon Valley—these 10 small towns are...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4 side hustles for recent college graduates: O...</td>\n",
       "      <td>4 Hours Ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>United Airlines will cut 12% of Newark flights...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headline         Time\n",
       "0   Netflix lays off 300 more employees as revenue...   19 Min Ago\n",
       "1   GOP draft bill would tighten rules for finance...   24 Min Ago\n",
       "2   Santoli: The S&P 500’s bounce is set to face a...   40 Min Ago\n",
       "3   Stocks making the biggest moves midday: WeWork...   44 Min Ago\n",
       "4   We're trimming a winner to raise some cash and...   49 Min Ago\n",
       "5           Intel warns Ohio factory could be delayed   52 Min Ago\n",
       "6   First half ranks among the market’s worst on r...   1 Hour Ago\n",
       "7   What we can learn about inflation, consumers f...   1 Hour Ago\n",
       "8   How to save money at the pump, with or without...   1 Hour Ago\n",
       "9   Instagram is testing new ways for teens to ver...  2 Hours Ago\n",
       "10  Proposed changes to retirement system get appr...  2 Hours Ago\n",
       "11  High inflation has 58% feeling insecure about ...  2 Hours Ago\n",
       "12  Supreme Court strikes down NY gun law restrict...  3 Hours Ago\n",
       "13  FDA bans Juul e-cigarettes as government pursu...  3 Hours Ago\n",
       "14  Tax return backlog is still 'crushing the IRS’...  3 Hours Ago\n",
       "15  Education Department to cancel student loan de...  3 Hours Ago\n",
       "16  Watch Jerome Powell testify to Congress on the...  3 Hours Ago\n",
       "17  Jan. 6 hearing to spotlight Trump's pressure o...  3 Hours Ago\n",
       "18  Warren Buffett buys another $500 million of Oc...  3 Hours Ago\n",
       "19  A 30-year Wall Street veteran on his tips for ...  3 Hours Ago\n",
       "20  Chinese EV maker Nio says a car fell from thir...  4 Hours Ago\n",
       "21  JPMorgan sees no recession, 28% S&P 500 comeba...  4 Hours Ago\n",
       "22  Chipotle restaurant in Maine becomes chain's f...  4 Hours Ago\n",
       "23  JPMorgan upgrades Funko, says toy stock has up...  4 Hours Ago\n",
       "24  What Cramer is watching Thursday — Meta's big ...  4 Hours Ago\n",
       "25  What Biden's upcoming student loan forgiveness...  4 Hours Ago\n",
       "26  Bethenny Frankel's top spending advice: 'It ha...  4 Hours Ago\n",
       "27  Forget Silicon Valley—these 10 small towns are...  4 Hours Ago\n",
       "28  4 side hustles for recent college graduates: O...  4 Hours Ago\n",
       "29  United Airlines will cut 12% of Newark flights...  5 Hours Ago"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Headline'] = headline\n",
    "df['Time'] = time\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c4276d",
   "metadata": {},
   "source": [
    "# 8. Most downloaded articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f2f4c383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7b9970f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(page.content,'html.parser')\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "13d117a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "for i in soup.find_all('h2',class_=\"sc-1qrq3sd-1 MKjKb sc-1nmom32-0 sc-1nmom32-1 hqhUYH ebTA-dR\"):\n",
    "    title.append(i.text)\n",
    "#title\n",
    "\n",
    "authors = []\n",
    "for i in soup.find_all('span',class_=\"sc-1w3fpd7-0 pgLAT\"):\n",
    "    authors.append(i.text)\n",
    "#authors\n",
    "\n",
    "date = []\n",
    "for i in soup.find_all('span',class_=\"sc-1thf9ly-2 bKddwo\"):\n",
    "    date.append(i.text)\n",
    "#date\n",
    "\n",
    "# I can't find the right tag for url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "718255c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Published date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>Silver, David, Singh, Satinder, Precup, Doina,...</td>\n",
       "      <td>Reward is enough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Making sense of raw input</td>\n",
       "      <td>Evans, Richard, Bošnjak, Matko and 5 more</td>\n",
       "      <td>Making sense of raw input</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Prakken, Henry, Sartor, Giovanni</td>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Boden, Margaret A.</td>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Lemaignan, Séverin, Warnier, Mathieu and 3 more</td>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Miller, Tim</td>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Making sense of sensory input</td>\n",
       "      <td>Evans, Richard, Hernández-Orallo, José and 3 more</td>\n",
       "      <td>Making sense of sensory input</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...</td>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Sutton, Richard S., Precup, Doina, Singh, Sati...</td>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Bard, Nolan, Foerster, Jakob N. and 13 more</td>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...</td>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "      <td>Bench-Capon, T.J.M., Dunne, Paul E.</td>\n",
       "      <td>Argumentation in artificial intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "      <td>Bošanský, Branislav, Lisý, Viliam and 3 more</td>\n",
       "      <td>Algorithms for computing strategies in two-pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Luo, Wenhan, Xing, Junliang and 4 more</td>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "      <td>Blum, Avrim L., Langley, Pat</td>\n",
       "      <td>Selection of relevant features and examples in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Arora, Saurabh, Doshi, Prashant</td>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Aas, Kjersti, Jullum, Martin, Løland, Anders</td>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...</td>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "      <td>Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.</td>\n",
       "      <td>Integrating social power into the decision-mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "      <td>Riveiro, Maria, Thill, Serge</td>\n",
       "      <td>“That's (not) the output I expected!” On the r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...</td>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "      <td>Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...</td>\n",
       "      <td>Algorithm runtime prediction: Methods &amp; evalua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Kohavi, Ron, John, George H.</td>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "      <td>Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...</td>\n",
       "      <td>Commonsense visual sensemaking for autonomous ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "      <td>Ying, Mingsheng</td>\n",
       "      <td>Quantum computation, quantum theory and AI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Paper title  \\\n",
       "0                                    Reward is enough   \n",
       "1                           Making sense of raw input   \n",
       "2   Law and logic: A review from an argumentation ...   \n",
       "3              Creativity and artificial intelligence   \n",
       "4   Artificial cognition for social human–robot in...   \n",
       "5   Explanation in artificial intelligence: Insigh...   \n",
       "6                       Making sense of sensory input   \n",
       "7   Conflict-based search for optimal multi-agent ...   \n",
       "8   Between MDPs and semi-MDPs: A framework for te...   \n",
       "9   The Hanabi challenge: A new frontier for AI re...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11           Argumentation in artificial intelligence   \n",
       "12  Algorithms for computing strategies in two-pla...   \n",
       "13      Multiple object tracking: A literature review   \n",
       "14  Selection of relevant features and examples in...   \n",
       "15  A survey of inverse reinforcement learning: Ch...   \n",
       "16  Explaining individual predictions when feature...   \n",
       "17  A review of possible effects of cognitive bias...   \n",
       "18  Integrating social power into the decision-mak...   \n",
       "19  “That's (not) the output I expected!” On the r...   \n",
       "20  Explaining black-box classifiers using post-ho...   \n",
       "21  Algorithm runtime prediction: Methods & evalua...   \n",
       "22              Wrappers for feature subset selection   \n",
       "23  Commonsense visual sensemaking for autonomous ...   \n",
       "24         Quantum computation, quantum theory and AI   \n",
       "\n",
       "                                              Authors  \\\n",
       "0   Silver, David, Singh, Satinder, Precup, Doina,...   \n",
       "1           Evans, Richard, Bošnjak, Matko and 5 more   \n",
       "2                   Prakken, Henry, Sartor, Giovanni    \n",
       "3                                 Boden, Margaret A.    \n",
       "4     Lemaignan, Séverin, Warnier, Mathieu and 3 more   \n",
       "5                                        Miller, Tim    \n",
       "6   Evans, Richard, Hernández-Orallo, José and 3 more   \n",
       "7   Sharon, Guni, Stern, Roni, Felner, Ariel, Stur...   \n",
       "8   Sutton, Richard S., Precup, Doina, Singh, Sati...   \n",
       "9         Bard, Nolan, Foerster, Jakob N. and 13 more   \n",
       "10  van der Waa, Jasper, Nieuwburg, Elisabeth, Cre...   \n",
       "11               Bench-Capon, T.J.M., Dunne, Paul E.    \n",
       "12       Bošanský, Branislav, Lisý, Viliam and 3 more   \n",
       "13             Luo, Wenhan, Xing, Junliang and 4 more   \n",
       "14                      Blum, Avrim L., Langley, Pat    \n",
       "15                   Arora, Saurabh, Doshi, Prashant    \n",
       "16      Aas, Kjersti, Jullum, Martin, Løland, Anders    \n",
       "17  Kliegr, Tomáš, Bahník, Štěpán, Fürnkranz, Joha...   \n",
       "18    Pereira, Gonçalo, Prada, Rui, Santos, Pedro A.    \n",
       "19                      Riveiro, Maria, Thill, Serge    \n",
       "20  Kenny, Eoin M., Ford, Courtney, Quinn, Molly, ...   \n",
       "21  Hutter, Frank, Xu, Lin, Hoos, Holger H., Leyto...   \n",
       "22                      Kohavi, Ron, John, George H.    \n",
       "23  Suchan, Jakob, Bhatt, Mehul, Varadarajan, Srik...   \n",
       "24                                   Ying, Mingsheng    \n",
       "\n",
       "                                       Published date  \n",
       "0                                    Reward is enough  \n",
       "1                           Making sense of raw input  \n",
       "2   Law and logic: A review from an argumentation ...  \n",
       "3              Creativity and artificial intelligence  \n",
       "4   Artificial cognition for social human–robot in...  \n",
       "5   Explanation in artificial intelligence: Insigh...  \n",
       "6                       Making sense of sensory input  \n",
       "7   Conflict-based search for optimal multi-agent ...  \n",
       "8   Between MDPs and semi-MDPs: A framework for te...  \n",
       "9   The Hanabi challenge: A new frontier for AI re...  \n",
       "10  Evaluating XAI: A comparison of rule-based and...  \n",
       "11           Argumentation in artificial intelligence  \n",
       "12  Algorithms for computing strategies in two-pla...  \n",
       "13      Multiple object tracking: A literature review  \n",
       "14  Selection of relevant features and examples in...  \n",
       "15  A survey of inverse reinforcement learning: Ch...  \n",
       "16  Explaining individual predictions when feature...  \n",
       "17  A review of possible effects of cognitive bias...  \n",
       "18  Integrating social power into the decision-mak...  \n",
       "19  “That's (not) the output I expected!” On the r...  \n",
       "20  Explaining black-box classifiers using post-ho...  \n",
       "21  Algorithm runtime prediction: Methods & evalua...  \n",
       "22              Wrappers for feature subset selection  \n",
       "23  Commonsense visual sensemaking for autonomous ...  \n",
       "24         Quantum computation, quantum theory and AI  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Paper title'] = title\n",
    "df['Authors'] = authors\n",
    "df['Published date'] = title\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6273b5",
   "metadata": {},
   "source": [
    "# 9. Restaurant details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "36aa93b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bc30dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(page.content,'html.parser')\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8b528811",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "for i in soup.find_all('div',class_=\"restnt-info cursor\"):\n",
    "    name.append(i.find('a').text)\n",
    "#name\n",
    "\n",
    "cuisine = []\n",
    "for i in soup.find_all('span',class_=\"double-line-ellipsis\"):\n",
    "    cuisine.append(i.find('a').text)\n",
    "#cuisine\n",
    "\n",
    "location = []\n",
    "for i in soup.find_all('div',class_=\"restnt-loc ellipsis\"):\n",
    "    location.append(i.text)\n",
    "#location\n",
    "\n",
    "ratings = []\n",
    "for i in soup.find_all('div',class_=\"restnt-rating rating-4\"):\n",
    "    ratings.append(i.text)\n",
    "#ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d1788ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castle Barbeque</td>\n",
       "      <td>Chinese</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cafe Knosh</td>\n",
       "      <td>Italian</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Barbeque Company</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India Grill</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi Barbeque</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que Village</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>World Cafe</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Vibe by The Lalit Traveller,Sector 35, Faridabad</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Indian Grill Room</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mad 4 Bar B Que</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>Sector 29, Faridabad</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Barbeque 29</td>\n",
       "      <td>North Indian</td>\n",
       "      <td>NIT, Faridabad</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Glasshouse</td>\n",
       "      <td>European</td>\n",
       "      <td>DoubleTree By Hilton Gurugram Baani Square,Sec...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Restaurant name       Cuisine  \\\n",
       "0                    Castle Barbeque  North Indian   \n",
       "1                    Jungle Jamboree  North Indian   \n",
       "2                    Castle Barbeque       Chinese   \n",
       "3                         Cafe Knosh       Italian   \n",
       "4               The Barbeque Company  North Indian   \n",
       "5                        India Grill  North Indian   \n",
       "6                     Delhi Barbeque  North Indian   \n",
       "7   The Monarch - Bar Be Que Village  North Indian   \n",
       "8                         World Cafe  North Indian   \n",
       "9                  Indian Grill Room  North Indian   \n",
       "10                   Mad 4 Bar B Que  North Indian   \n",
       "11                       Barbeque 29  North Indian   \n",
       "12                        Glasshouse      European   \n",
       "\n",
       "                                             Location Ratings  \n",
       "0                      Connaught Place, Central Delhi     3.5  \n",
       "1              3CS Mall,Lajpat Nagar - 3, South Delhi     3.9  \n",
       "2              Pacific Mall,Tagore Garden, West Delhi     3.9  \n",
       "3   The Leela Ambience Convention Hotel,Shahdara, ...     4.3  \n",
       "4                  Gardens Galleria,Sector 38A, Noida       4  \n",
       "5                Hilton Garden Inn,Saket, South Delhi     3.9  \n",
       "6      Taurus Sarovar Portico,Mahipalpur, South Delhi     3.7  \n",
       "7   Indirapuram Habitat Centre,Indirapuram, Ghaziabad     3.8  \n",
       "8    Vibe by The Lalit Traveller,Sector 35, Faridabad     4.3  \n",
       "9    Suncity Business Tower,Golf Course Road, Gurgaon     4.3  \n",
       "10                               Sector 29, Faridabad     3.6  \n",
       "11                                     NIT, Faridabad     4.2  \n",
       "12  DoubleTree By Hilton Gurugram Baani Square,Sec...       4  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"Restaurant name\"] = name\n",
    "df['Cuisine'] = cuisine\n",
    "df['Location'] = location\n",
    "df['Ratings'] = ratings\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82de2f1a",
   "metadata": {},
   "source": [
    "# 10. Top publications from Google Scholar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bc743da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get('https://scholar.google.com/citations?view_op=top_venues&hl=en')\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "37b0dc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(page.content,'html.parser')\n",
    "#soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7303b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = []\n",
    "for i in soup.find_all('td',class_=\"gsc_mvt_p\"):\n",
    "    rank.append(i.text)\n",
    "#rank\n",
    "\n",
    "publication = []\n",
    "for i in soup.find_all('td',class_=\"gsc_mvt_t\"):\n",
    "    publication.append(i.text)\n",
    "#publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a25b4f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Publication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Nature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>The New England Journal of Medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>IEEE/CVF Conference on Computer Vision and Pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>The Lancet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.</td>\n",
       "      <td>Frontiers in Immunology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.</td>\n",
       "      <td>Nature Immunology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.</td>\n",
       "      <td>JAMA Oncology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.</td>\n",
       "      <td>The Lancet Neurology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                                        Publication\n",
       "0     1.                                             Nature\n",
       "1     2.                The New England Journal of Medicine\n",
       "2     3.                                            Science\n",
       "3     4.  IEEE/CVF Conference on Computer Vision and Pat...\n",
       "4     5.                                         The Lancet\n",
       "..   ...                                                ...\n",
       "95   96.                            Frontiers in Immunology\n",
       "96   97.                                              Small\n",
       "97   98.                                  Nature Immunology\n",
       "98   99.                                      JAMA Oncology\n",
       "99  100.                               The Lancet Neurology\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"Rank\"] = rank\n",
    "df[\"Publication\"]  = publication\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec046b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
